#Intial Setup
setwd("M:\\ISA591\\Project")
getwd()
options(scipen=999)
dom<-read.csv("domestic_data.csv")
dom$Tag<-dom$?..tag
dom18<-read.csv("domestic_2018.csv")
dom18$MiamiRanks<-as.factor(dom18$MiamiRanks)
dom18$DateFrom<-rep("2018", length(dom18$Tag))
summary(dom18$DateFrom)
dom18$DateFrom<-as.factor(dom18$DateFrom)

#join datasets together
join<-merge(dom, dom18, all=TRUE)
summary(join$Column.58)
summary(join$?..tag)
dom18$Column.58



#Prepare for income data
join$Zip<-as.character(join$Zip)
join$Zip5<-as.character(join$Zip5)
ind<-which(is.na(join$Zip))
join$Zip[ind]<-join$Zip5[ind]
join$Zip<-as.factor(join$Zip)
summary(join$Zip)


#Variable removal:
library(dplyr)
join<-select(join, -?..tag, -Column.58, -StateResidency, -ApplicationDate,-ApplicationDate_Formatted,
             -Decision, -DecisionDate, -DecisionDate_Formatted,-High.School.Type.Slate,
             -DecisionDateFormatted, -ConfirmCode, -MeritGPAThresholdFlag,
             -MeritGPA, -GPAOrig, -GPAScale,-OriginalGPA, -RoundedGPA,-ACTChoice,
             -ACTComposite, -ACTEng, -ACTMath, -ACTRdng, -ACTSci, -ACTWRSC,
             -SATVerbal, -SATMath, -SATWRSC, -HighSchoolCode, -ConCode, -CanCode,
             -TermCode, -CountyCode, -Geomkt,-Status, -Retained_recode,
             -StateResidency,-College.Since.9th.Grade,-SuppMajor1,-SuppMajor2,-SuppMajor3,
             -Parent1Degree,-Parent2Degree,-EER,-ACEFlag, -HighSchoolState,
             -MCFlag, -SuppMajor2, -SuppMajor3,-Zipcode,
             -DisciplinaryQuestion1,-TOEFL.Total,-TOEFL.Listening,-TOEFL.Reading,
             -TOEFL.Speaking,-TOEFL.Structure.Written.Expression,-IELTS.Overall.Band.Score,
             -IELTS.Reading,-IELTS.Listening,-IELTS.Writing,-IELTS.Speaking,
             -SAT.R.ERW,-SAT.R.Math,-ACTMaxComposite,-ACTMaxEnglish,-ACTMaxMath,
             -ACTMaxReading, -ACTMaxSciReasoning,-ACTWritingMax,-TOEFL.Total,-Tag,
             -ZipCode,-Phone,-Question, -ACTEquivalent,-SATComp,
             -Math,-Lang,-Satv25,-Satv75,-Satm25,-Satm75,-Act25,-Act75,-County,
             -Dec, -InitialContact,-hs.code,-HSClust,-EduNbrhd,-TIBR,-TIBL,
             -TIBS,-TIBW,-TIBT,-IELL,-IELR,-IELW,-IELS,-IELO,-TCP1,-TCP2,-TCP3,
             -TCP4,-TCPT,-MAI,-FSBDirect,-StudentType,-CEEB1,-CEEB2,-CEEB3,
             -CEEB4,-CEEB5,-CEEB6,-CEEB7,-CEEB8,-CEEB9,-CEEB10,-WhichTestBest,
             -HS.Code,-IntlTestScoreThresholdFlag,-FirstSchool,-SecondSchool,
             -ThirdSchool, -FourthSchool, -FifthSchool, -SixthSchool,-SeventhSchool,
             -EighthSchool,-TenthSchool,-Com.App.Acad.Int,-Super.ACT,-X__1,
             -Primary_Parent_Occupation,-Sec_Parent_Occupation,-Permanent.Home,
             -AIDY_Code,-FAFSA_RECV_Date,-Which.Test,-Language,-DEC,-Class.Percentile)



#RACE
join$AI_Race<-as.character(join$AI_Race)
join$Race<-as.character(join$Race)
ind<-which(is.na(join$Race))
join$Race[ind]<-join$AI_Race[ind]
join$Race<-as.factor(join$Race)
summary(join$Race)

join$AS_Race<-as.character(join$AS_Race)
join$Race<-as.character(join$Race)
ind<-which(is.na(join$Race))
join$Race[ind]<-join$AS_Race[ind]
join$Race<-as.factor(join$Race)
summary(join$Race)

join$BL_Race<-as.character(join$BL_Race)
join$Race<-as.character(join$Race)
ind<-which(is.na(join$Race))
join$Race[ind]<-join$BL_Race[ind]
join$Race<-as.factor(join$Race)
summary(join$Race)

join$HS_Race<-as.character(join$HS_Race)
join$Race<-as.character(join$Race)
ind<-which(is.na(join$Race))
join$Race[ind]<-join$HS_Race[ind]
join$Race<-as.factor(join$Race)
summary(join$Race)

join$PI_Race<-as.character(join$PI_Race)
join$Race<-as.character(join$Race)
ind<-which(is.na(join$Race))
join$Race[ind]<-join$PI_Race[ind]
join$Race<-as.factor(join$Race)
summary(join$Race)

join$WH_Race<-as.character(join$WH_Race)
join$Race<-as.character(join$Race)
ind<-which(is.na(join$Race))
join$Race[ind]<-join$WH_Race[ind]
join$Race<-as.factor(join$Race)
summary(join$Race)

join$Race<-recode_factor(join$Race, "1"="AI")
join$Race<-recode_factor(join$Race, "2"="AS")
join$Race<-recode_factor(join$Race, "3"="BL")
join$Race<-recode_factor(join$Race, "4"="PI")
join$Race<-recode_factor(join$Race, "5"="WH")
join$Race<-recode_factor(join$Race, "6"="HS")
join$Race<-recode_factor(join$Race, "7"="MR")
join$Race<-recode_factor(join$Race, "8"="UK")
join$Race<-recode_factor(join$Race, "9"="NR")
join$Race<-recode_factor(join$Race, "American Indian or Alaska Native"="AI")
join$Race<-recode_factor(join$Race, "Asian"="AS")
join$Race<-recode_factor(join$Race, "Black or African American"="BL")
join$Race<-recode_factor(join$Race, "Native Hawaiian or Other Pacific Islander"="PI")
join$Race<-recode_factor(join$Race, "White"="WH")
join$Race<-recode_factor(join$Race, "Hispanic/Latino"="HS")
join$Race<-recode_factor(join$Race, "Hispanic"="HS")
join$Race<-recode_factor(join$Race, "Multi Racial"="MR")
join$Race<-recode_factor(join$Race, "Unknown"="UK")
join$Race<-recode_factor(join$Race, "Non-Resident Alien"="NR")
join$Race<-recode_factor(join$Race, "SortOfIntl"="NC")
join$Race<-recode_factor(join$OneRace, "Two or more races"="MR")
#10 factors with 17323 NAs ---removed after subset
summary(join$Race)

join$Race<-recode_factor(join$Race, "PR"="HS")
join$Race<-recode_factor(join$Race, "MA"="HS")

#Year subset----go with everything from 2011
#Date from good for join, data from has NAs
#this is due to bad years that impacted 4 years total from 05-10, meaning only missing "good years" of 07 and 08
#ACT score is not significantly different in subseted data set, so choosing 2011 as opposed to 2013

#this is where things are going different, including 07 and 08
#3627 NAs from 2018 data 
#install.packages("tidyverse")
library(tidyverse)
join$DateFrom<-as.factor(join$DateFrom)
'%notin%'<-Negate('%in%')
join<-join %>% filter(join$DateFrom %notin% c(2005,2006,2009,2010))
summary(join$DateFrom)

summary(join$Race)
join$Race[join$Race==""]<-NA
join$Race<-as.character(join$Race)
join$Race[is.na(join$Race)]<-"UK"
join$Race<-as.factor(join$Race)





join<-select(join, -AS_Race,-AI_Race,-OneRace, -BL_Race,-HS_Race,
              -PI_Race,-FullRace, -WH_Race)
summary(join$Race)
join<-select(join, -AlmostFullRace,-DataFrom,-Ethn_HS_YN,
              -FullEthn.Race, -FullEthn,-Hispanic)


#Special Consideration?
summary(join$Special.Consideration)

join$Special.Consideration<-as.character(join$Special.Consideration)
join$SpecialConsideration<-as.character(join$SpecialConsideration)
ind<-which(is.na(join$SpecialConsideration))
join$SpecialConsideration[ind]<-join$Special.Consideration[ind]
join$SpecialConsideration<-as.factor(join$SpecialConsideration)
summary(join$SpecialConsideration)

join$SpecialConsideration<-recode_factor(join$SpecialConsideration,
                                     "CA"="Other",
                                     "DI"="Other","ES"="Other",
                                     "FC"="Other","FI"= "Other","FM"="Other",
                                     "FR"="Other","FT"="Other","PR"="Other")

join$SpecialConsideration[join$SpecialConsideration==""]<-NA
join$SpecialConsideration<-as.character(join$SpecialConsideration)
join$SpecialConsideration[is.na(join$SpecialConsideration)]<-"N"
join$SpecialConsideration<-as.factor(join$SpecialConsideration)


test<-join
#Outside data
library("readxl")
inc<-read_xlsx("MedianInByZip.xlsx")
inc$ZipUse<-as.factor(inc$ZipUse)
library("sqldf")
join = sqldf("Select * from test
             LEFT JOIN inc
             on test.Zip = inc.ZipUse")

summary(join$medianIncome)
summary(join$meanIncome)


#Alumni Connection
str(join$AlumniConnection)
summary(join$AlumniConnection)
join$AlumniConnection<-recode_factor(join$AlumniConnection,
                                      "A - Mother, Father, Sibling"="Y",
                                      "B - Mother, Father"="Y","C - Mother, Sibling"="Y",
                                      "D - Father, Sibling"="Y","F - Father"= "Y","M - Mother"="Y",
                                      "O - Other"="Y","S - Sibling"="Y","S"="Y","O"="Y","M"="Y",
                                      "F"="Y","D"="Y","C"="Y","B"="Y","A"="Y")

join$AlumniConnection[join$AlumniConnection==""]<-NA
join$AlumniConnection<-as.character(join$AlumniConnection)
join$AlumniConnection[is.na(join$AlumniConnection)]<-"N"
join$AlumniConnection<-as.factor(join$AlumniConnection)


#Homestate
join$HomeState<-as.character(join$HomeState)
join$HomeState[is.na(join$HomeState)]<-"UK"
join$HomeState<-as.factor(join$HomeState)
str(join$HomeState)

summary(join$HomeState)
dum<-model.matrix(~0+HomeState, data=join)
dum<-as.data.frame(dum)
join$HomeState_OH<-as.factor(dum$HomeStateOH)
join$HomeState_IL<-as.factor(dum$HomeStateIL)
join$HomeState_MI<-as.factor(dum$HomeStateMI)
join$HomeState_IN<-as.factor(dum$HomeStateIN)
join$HomeState_PA<-as.factor(dum$HomeStatePA)
join$HomeState_NY<-as.factor(dum$HomeStateNY)
join$HomeState_CT<-as.factor(dum$HomeStateCT)
join$HomeState_MO<-as.factor(dum$HomeStateMO)

#FirstGen
summary(join$FirstGen)
join$FirstGen[join$FirstGen==""]<-NA
join$FirstGen<-as.character(join$FirstGen)
join$FirstGen[is.na(join$FirstGen)]<-"N"
join$FirstGen<-as.factor(join$FirstGen)


#Application Type
join$ApplicationType<-recode_factor(join$ApplicationType,
                                      "OE"="Early","OF"="Feb",
                                     "OM"="Mar","OI"="Int")
summary(join$ApplicationType)
                                    
#Decision Type-code for transforming blanks/nas                                                                       "OM"="Mar","OI"="Int")
summary(join$DecisionType)
join$DecisionType[join$DecisionType==""]<-NA
join$DecisionType<-as.character(join$DecisionType)
join$DecisionType[is.na(join$DecisionType)]<-"UK"
join$DecisionType<-as.factor(join$DecisionType)
str(join$DecisionType)

join$DecisionType<-recode_factor(join$DecisionType,
                                     "DN"="UK","DQ"="D",
                                     "DY"="D","E"="D",
                                  "HN"="H","HQ"="H",
                                  "HY"="H","N"="UK",
                                  "SQ"="S","SY"="S","KN"="K",
                                 "KQ"="K","KY"="K","SN"="S")
summary(join$DecisionType)                             



#Confirm Date 
library(lubridate)
date<-ymd(join$ConfirmDate)
summary(join$ConfirmDate)
summary(date)
contact_month<-as.factor(month(date))
join$confirm_month<-contact_month

summary(join$confirm_month)
join$confirm_month<-as.character(join$confirm_month)
join$confirm_month[is.na(join$confirm_month)]<-"UK"
join$confirm_month<-as.factor(join$confirm_month)
summary(join$confirm_month)

join$confirm_month<-recode_factor(join$confirm_month,
                        "1"="Jan","2"="Feb","3"="Mar","4"="Apr",
                        "5"="May","6"="Jun","7"="Jul","8"="Aug","12"="Dec")
summary(join$confirm_month)

#Get rid of more
join<-select(join, -ConfirmDate,-ConfirmDate_Formatted,
              -ConfirmedDate, -Confirmed.Date,-Bridges,
              -Harrison,-NatlHisp, -NatlAch,-SummerScholars,
              -VentureScholar)


#Major
library("readxl")
maj<-read_xlsx("Major_Codes_and_Descriptions.xlsx")
library("sqldf")
test<-join
join = sqldf("Select * from test
             LEFT JOIN maj
             on test.Major = maj.STVMAJR_CODE")

join$STVMAJR_DESC<-as.factor(join$STVMAJR_DESC)
join$Major<-as.factor(join$Major)
summary(join$STVMAJR_DESC)
summary(join$Major)

#Condensing two vars into one code---works
join$STVMAJR_DESC<-as.character(join$STVMAJR_DESC)
join$Major<-as.character(join$Major)
ind<-which(is.na(join$STVMAJR_DESC))
join$STVMAJR_DESC[ind]<-join$Major[ind]
join$STVMAJR_DESC<-as.factor(join$STVMAJR_DESC)
summary(join$STVMAJR_DESC)
join<-join %>% rename(major = STVMAJR_DESC)


dum<-model.matrix(~0+major, data=join)
dum<-as.data.frame(dum)
join$major_UNI<-as.factor(dum$`majorUniversity Studies`)
join$major_ECO<-as.factor(dum$`majorBusiness Economics`)
join$major_BU<-as.factor(dum$`majorUndeclared - Business`)
join$major_PSY<-as.factor(dum$majorPsychology)
join$major_FIN<-as.factor(dum$majorFinance)
join$major_UDC<-as.factor(dum$major56)
join$major_BIO<-as.factor(dum$majorBiology)
join$major_MKT<-as.factor(dum$majorMarketing)
join$major_ACC<-as.factor(dum$majorAccountancy)
join$major_POL<-as.factor(dum$`majorPolitical Science`)
join$major_ZOO<-as.factor(dum$majorZoology)
join$major_ECE<-as.factor(dum$`majorEarly Childhood Education`)
join$major_BCH<-as.factor(dum$majorBiochemistry)
#UDC= undecided, ece= early childhood education, bch=biochemistry

#ON
#ON=1 basically stand-in for merit scholarship (high likelyhood)
join$ON<-as.factor(join$ON)
summary(join$ON)
join$ON<-recode_factor(join$ON,
                                     "5"="4","6"="4",
                                     "7"="4","8"="4")
join$ON<-as.character(join$ON)
join$ON[is.na(join$ON)]<-"UK"
join$ON<-as.factor(join$ON)
summary(join$ON)


#Concentration
join$Concentration<-as.character(join$Concentration)
join$Concentration[is.na(join$Concentration)]<-"UK"
join$Concentration<-as.factor(join$Concentration)
summary(join$Concentration)
dum<-model.matrix(~0+Concentration, data=join)
dum<-as.data.frame(dum)
join$Concentration_BB<-as.factor(dum$ConcentrationBB)
join$Concentration_PM<-as.factor(dum$ConcentrationPM)
join$Concentration_UK<-as.factor(dum$ConcentrationUK)

#GPA--says it is rescaled for 4 scale, but there are 117 values over 5
#if function for numeric?
join$GPA<-as.numeric(join$GPA)
str(join$GPA)
summary(join$GPA)



#Parent Education-combined into if at least one went to college
join$Parent.1.Education.Level<-as.character(join$Parent.1.Education.Level)
join$Parent.2.Educational.Level<-as.character(join$Parent.2.Educational.Level)
ind<-which(is.na(join$Parent.1.Education.Level))
join$Parent.1.Education.Level[ind]<-join$Parent.2.Educational.Level[ind]
join$Parent.1.Education.Level<-as.factor(join$Parent.1.Education.Level)
summary(join$Parent.1.Education.Level)

join$Parent.1.Education.Level<-recode_factor(join$Parent.1.Education.Level,
                                      "Completed grade/primary school"="N",
                                      "Graduate school"="Y","Graduated from college/university"="Y",
                                      "Graduated from high/secondary school (or equivalent)"="N",
                                      "Graduated trade school"= "N","None"="N",
                                      "Some college/university"="N","Some grade/primary school"="N",
                                      "Some high/secondary school"="N","Some trade school"="N")
join$Parent.1.Education.Level[join$Parent.1.Education.Level==""]<-NA
join$Parent.1.Education.Level<-as.character(join$Parent.1.Education.Level)
join$Parent.1.Education.Level[is.na(join$Parent.1.Education.Level)]<-"UK"
join$Parent.1.Education.Level<-as.factor(join$Parent.1.Education.Level)
join<-join %>% rename(Parent.College.Grad = Parent.1.Education.Level)
summary(join$Parent.College.Grad)


#Housing
join$Housing<-as.character(join$Housing)
join$Housing[is.na(join$Housing)]<-"UK"
join$Housing<-as.factor(join$Housing)
summary(join$Housing)
join$Housing<-recode_factor(join$Housing,
                        "EV"="On Campus","NO"="Off Campus")

#AcadRS
summary(join$AcadRS)



#County
summary(join$CountyDesc)
join$CountyDesc<-as.character(join$CountyDesc)
join$CountyDesc[is.na(join$CountyDesc)]<-"UK"
join$CountyDesc<-as.factor(join$CountyDesc)
str(join$CountyDesc)

join$CountyDesc<-recode_factor(join$CountyDesc,
                             "Hamilton, OH"="Hamilton County, OH",
                             "Franklin, OH"="Franklin County, OH",
                             "Cuyahoga, OH"="Cuyahoga County, OH",
                             "Butler, OH"="Butler County, OH",
                             "Cook, IL"="Cook County, IL",
                             "Warren, OH"="Warren County, OH",
                             "Montgomery, OH"="Montgomery County, OH",
                             "Delaware, OH"="Delaware County, OH")

dum<-model.matrix(~0+CountyDesc, data=join)
dum<-as.data.frame(dum)
join$county_Hamilton_OH<-as.factor(dum$`CountyDescHamilton County, OH`)
join$county_Franklin_OH<-as.factor(dum$`CountyDescFranklin County, OH`)
join$county_Cuyahoga_OH<-as.factor(dum$`CountyDescCuyahoga County, OH`)
join$county_Butler_OH<-as.factor(dum$`CountyDescButler County, OH`)
join$county_Warren_OH<-as.factor(dum$`CountyDescWarren County, OH`)
join$county_Cook_IL<-as.factor(dum$`CountyDescCook County, IL`)
join$county_Montgomery_OH<-as.factor(dum$`CountyDescMontgomery County, OH`)
join$county_Delaware_OH<-as.factor(dum$`CountyDescDelaware County, OH`)



#County region
summary(join$OhioCountyRegion)
join$OhioCountyRegion[join$OhioCountyRegion==""]<-NA
join$OhioCountyRegion<-as.character(join$OhioCountyRegion)
join$OhioCountyRegion[is.na(join$OhioCountyRegion)]<-"UK"
join$OhioCountyRegion<-as.factor(join$OhioCountyRegion)
summary(join$OhioCountyRegion)

#US region
join$USStateRegion<-as.factor(join$USStateRegion)
summary(join$USStateRegion)
join$USStateRegion[join$USStateRegion==""]<-NA
join$USStateRegion<-as.character(join$USStateRegion)
join$USStateRegion[is.na(join$USStateRegion)]<-"UK"
join$USStateRegion<-as.factor(join$USStateRegion)

join$USStateRegion<-recode_factor(join$USStateRegion,
                                "International"="Other",
                                "Western Midwest"="W Midwest",
                                "Eastern Midwest"="E Midwest",
                                "Middle Atlantic"="Mid Atlantic")



#Intl Students
summary(join$NationDesc)
join$NationDesc<-as.character(join$NationDesc)
join$NationDesc[is.na(join$NationDesc)]<-"UK"
join$NationDesc<-as.factor(join$NationDesc)

join$NationDesc<-recode_factor(join$NationDesc,
                                "Vietnam"="Asia",
                                "India"="Asia",
                                "Hong Kong S.A.R."="Asia",
                                "Japan"="Asia",
                                "Hong Kong"="Asia",
                                "China"="Asia",
                                "Indonesia"="Asia",
                                "South Korea"="Asia")

dum<-model.matrix(~0+NationDesc, data=join)
dum<-as.data.frame(dum)
join$NationDesc_Asia<-as.factor(dum$NationDescAsia)


#HS Type
summary(join$HsType)
join$HsType[join$HsType==""]<-NA
join$HsType<-as.character(join$HsType)
join$HsType[is.na(join$HsType)]<-"UK"
join$HsType<-as.factor(join$HsType)

join$HsType<-recode_factor(join$HsType,
                                "Unknown"="UK",
                                "1"="Public",
                                "2"="Private Secular",
                                "3"="Religious",
                                "4"="Religious")

#Miami Ranks Missing
summary(join$MiamiRanks)
join$MiamiRanks[join$MiamiRanks==""]<-NA

join$MiamiRanks<-as.character(join$MiamiRanks)
join$MiamiRanks[is.na(join$MiamiRanks)]<-"UK"
join$MiamiRanks<-as.factor(join$MiamiRanks)


#Missing value indicator for median income 
summary(join$medianIncome)
join$M_medianIncome<-as.factor(ifelse(is.na(join$medianIncome),1,0))
summary(join$M_medianIncome)
join$medianIncome[is.na(join$medianIncome)]<-median(join$medianIncome, na.rm=TRUE)
summary(join$medianIncome)

#Division
summary(join$Division)
join$Division<-recode_factor(join$Division,
                            "BU"="FSB",
                            "EA"="CEHS",
                            "AP"="CEC",
                            "FA"="CCA",
                            "AS"="CAS",
                            "0"="UK",
                            "IS"="UK",
                            "CLAAS"="UK",
                            "EHS"="CEHS")



#Could also create missing value indicators for GPA, ACAD_RS

summary(join$GPA)
join$GPA[is.na(join$GPA)]<-median(join$GPA, na.rm=TRUE)
summary(join$GPA)

summary(join$AcadRS)
join$AcadRS[is.na(join$AcadRS)]<-median(join$AcadRS, na.rm=TRUE)
summary(join$AcadRS)

#Rank percent
summary(join$RankPercent)
join$M_rankPercent<-as.factor(ifelse(is.na(join$RankPercent),1,0))
summary(join$M_rankPercent)



#Class Size
summary(join$ClassSize)
join$M_classSize<-as.factor(ifelse(is.na(join$ClassSize),1,0))
summary(join$M_classSize)
join$ClassSize[is.na(join$ClassSize)]<-median(join$ClassSize, na.rm=TRUE)
summary(join$ClassSize)


#Pop
summary(join$Pop)
join$M_pop<-as.factor(ifelse(is.na(join$Pop),1,0))
summary(join$M_pop)
join$Pop[is.na(join$Pop)]<-median(join$Pop, na.rm=TRUE)
summary(join$Pop)




#join Removal
join<-select(join, -RankPercent, -ClassRank,-Major,-HomeState,-CountyDesc,-Country,-Citizen,-InternationalFlag,
              -Zip5, -Special.Consideration,-Parent.2.Educational.Level,-NationDesc,-SpecialConsideration,
              -VisaType,-Visa.Type,-Zip,-Intl.Scholarship,-Citizenship,-Citizenship1,-Citizenship2,
              -ZipUse,-meanIncome,-STVMAJR_CODE,-major,-Concentration)



#ALL DATA PREPROCESSING GOOD FROM HERE 
saveRDS(join, "join.RDS")
join<-readRDS("join.RDS")

#FINAL INCLUDES 2007 AND 2008, FINAL.1 ONLY>2010
#Exlude 2018 data from model building samples
final<-subset(join, DateFrom != 2018)
summary(final$DateFrom)

#Use only data after 2010
final.1<-final
final.1<-subset(final.1, DateFrom!=2007)
final.1<-subset(final.1, DateFrom!=2008)
summary(final.1$DateFrom)

#Fixing retained
summary(final$retained)
final<-subset(final, retained<35)
final$retained<-as.factor(final$retained)
final$retained<-recode_factor(final$retained,
                             "0"="No","1"="Yes")
summary(final$retained)


#Final.1 retained
summary(final.1$retained)
final.1<-subset(final.1, retained<35)
final.1$retained<-as.factor(final.1$retained)
final.1$retained<-recode_factor(final.1$retained,
                              "0"="No","1"="Yes")
summary(final.1$retained)

##Review
source("M:\\ISA591\\Class Scripts\\Data Summary by Weese.R") 
data.summary(final.1)

#retained should be that yes is less while no is more
summary(final$retained)
final$retained<-recode_factor(final$retained,
                                "Yes"="No","No"="Yes")
data.summary(final)

saveRDS(final, "final.RDS")
final<-readRDS("final.RDS")




########################PHASE 2#############################

###GOAL=PREDICT RETENTION 
#DO NOT USE final.1



summary(final$retained)
final$retained<-relevel(final$retained, ref = "Yes")

#Training and Validation using 2017 as validation data
#final.years<-final
#set.seed(13)
#summary(final.years$DateFrom)
#final.train<-subset(final.years, DateFrom !=2017)
#final.valid<-subset(final.years, DateFrom == 2017)

###Create hold out sample--doesn't use 2017 as validation
#set.seed(100)
#index<-sample(1:nrow(final), size=2500, replace=FALSE)
#final.hold<-final[index,]
#final.data<-final[-index,]

###CREATE OVERSAMPLED DATA
#Use 2017 as validation data then oversample from remaining years
#final.data.split<-split(final.data, final.data$retained)
#retained<-final.data.split[[1]]
#not.retained<-final.data.split[[2]]
#index<-sample(1:nrow(retained), size=3*nrow(not.retained), replace=FALSE)
#data0<-retained[index,]
#final.data.os<-rbind(not.retained, data0)
#summary(final.data.os)
#Training and validation using oversampled data
#trainIndex<-sample(1:nrow(final.data.os), size=round(0.8*nrow(final.data.os)), replace = F)
#final.train<-final.data[trainIndex,]
#final.valid<-final.data[-trainIndex,]
#Gets rid of variables that only have one level due to oversampling
#final.train<-select(final.train, -major_BIO,-Parent.College.Grad)

#Training and validation without using oversampled data
trainIndex<-sample(1:nrow(final), size=round(0.75*nrow(final)), replace = F)
final.train<-final[trainIndex,]
final.valid<-final[-trainIndex,]

#library(dplyr)
#use final.data (all years not 2017 for training, final.valid for validation)


summary(final.train)

#Stepwise model
full<-glm(retained~., data=final.train, family="binomial")
null<-glm(retained~1, data=final.train, family="binomial")
step.1<-step(null, list(lower=formula(null), upper=formula(full)), data=final.train, direction="both", trace=0)
summary(step.1)

#valid is from a distribution of all years
library(pROC)
p.step.valid<-predict(step.1, newdata=final.valid, type="response")
r.step.valid<-roc(final.valid$retained, p.step.valid)
r.step.valid$auc
#valid step auc is 0.6368

df_step.1<-step.1$df.null-step.1$df.residual
df_step.1


#Reduced stepwise model
full<-glm(retained~GPA+ApplicationType+FirstGen+DecisionType+AlumniConnection
          +HomeState_IL+AcadRS+county_Butler_OH+Division+Housing+ClassSize+medianIncome+
            HomeState_NY+HsType+ACTBest, data=final.train, family="binomial")
null<-glm(retained~1, data=final.train, family="binomial")
step.2<-step(null, list(lower=formula(null), upper=formula(full)), data=final.train, direction="both", trace=0)
summary(step.2)

#valid is from a distribution of all years
library(pROC)
p.step.valid.2<-predict(step.2, newdata=final.valid, type="response")
r.step.valid.2<-roc(final.valid$retained, p.step.valid.2)
r.step.valid.2$auc
#valid step auc is 0.6374

df_step.2<-step.2$df.null-step.2$df.residual
df_step.2



#Second order stepwise regression needs to be run-
formula(step.1)
f<-formula(retained ~ (GPA + ApplicationType + FirstGen + DecisionType + ClassSize+medianIncome+
                         AlumniConnection + HomeState_IL + county_Butler_OH + ON+
                         Division + Housing + AcadRS + HomeState_NY + HsType + ACTBest)^2)
full<-glm(f, data=final.train, family="binomial")
step.3<-step(null, list(lower=formula(null), upper=formula(full)), data=final.train, direction="both", trace=0)
summary(step.3)


p.step.valid.3<-predict(step.3, newdata=final.valid, type="response")
r.step.valid.3<-roc(final.valid$retained, p.step.valid.3)
r.step.valid.3$auc
#valid step auc = 0.6371

df_step.3<-step.3$df.null-step.3$df.residual
df_step.3


#Select best stepwise function for this terms to use in NN
terms = attr(step.2$terms, "term.labels")
terms
length(terms)


#Don't use decision tree




#random forest 
library(randomForest)
library(caret)

kvalues<-c(5, 10, 20, 30, 40, 50)
tunegrid <- data.frame(.mtry=kvalues)
set.seed(13)
cvindx<-createFolds(index, k=10, returnTrain = TRUE)
ctrl <- trainControl(method="cv", index=cvindx)
#increasing k makes model perform worse

library(doParallel)
detectCores() #CHANGE FOR LAPTOP

#instead of [-21] take a subset of final.train without retained value
library(dplyr)
noRetained<-select(final.train,-retained)
noRetained<-subset(final.train, select = -retained)

cl <- makePSOCKcluster(6) 
registerDoParallel(cl)
rforest<-train(x=noRetained, y=final.train$retained, data=final.train, method="rf", tuneGrid=tunegrid, ntree=500, trControl=ctrl )
stopCluster(cl)

rforest

#Validation
p.rforest.v<-predict(rforest, newdata=final.valid, type = "prob")
r.v<-roc(final.valid$retained, p.rforest.v[,2])
v.rforest.auc<-r.v$auc
v.rforest.auc
#auc=0.5928

#Variable Importance
varI<-varImp(rforest)
varI
var<-as.data.frame(varI$importance)
var <- cbind(rownames(var), data.frame(var, row.names=NULL))

head(varI$importance)
plot(varI, cex=0.2)
var <- var[order(-var$Overall), ]
terms.rf<-var$`rownames(var)`[1:25, drop=TRUE]
terms.rf





#Bagged Tree
library(ipred)
library(rpart)
library(pROC)
baggedTree<-bagging(retained~., data=final.train, nbagg=100, control=rpart.control(cp=0.001, xval=10), coob=TRUE)
p.bag<-predict(baggedTree, newdata=final.valid, type="prob")

r.b<-roc(final.valid$retained,  p.bag[,2])
p.bag.auc<-r.b$auc
p.bag.auc
#bagged tree auc=0.58



#Boosted tree
library(gbm)
set.seed(13)

Grid <- expand.grid(n.trees = seq(50,250,50), interaction.depth = c(20, 40), shrinkage = c(0.01, 0.001), n.minobsinnode=c(25))
set.seed(13)
cvindx<-createFolds(index, k=10, returnTrain = TRUE)
ctrl <- trainControl(method="cv", index=cvindx, summaryFunction = twoClassSummary, classProbs = TRUE)

cl <- makePSOCKcluster(6) #starts the cluster
registerDoParallel(cl)
gb.tree <- train(retained~., data=final.train, method = 'gbm', trControl=ctrl, tuneGrid=Grid, metric='ROC')
stopCluster(cl)

gb.tree

p.gbtree<-predict(gb.tree, newdata=final.valid, type="prob")
r.boost<-roc(final.valid$retained,  p.gbtree[,2])
r.gbtree.auc<-r.boost$auc
r.gbtree.auc
#boosted tree auc=0.642





#Neural Net
library(nnet)
library(caret)
set.seed(13)
cvindx<-createFolds(index, k=10, returnTrain = TRUE)
ctrl <- trainControl(method="cv", index=cvindx, summaryFunction = twoClassSummary, classProbs = TRUE)

tunegrid<-expand.grid( .size=1:20, .decay= c(0, 0.1, 0.5 , 0.9,1))
maxSize<-max(tunegrid$.size)
summary(final.train$retained)
numWts<-800


#Log NN
cl <- makePSOCKcluster(6) #Starts the parallel computing
registerDoParallel(cl)

nnetFit<-train(x=final.train[,terms], y=final.train$retained, 
               method="nnet", 
               metric="ROC", 
               linout=FALSE,
               preProcess = c("range"), 
               tuneGrid = tunegrid, 
               
               trace=FALSE,
               maxit=100,
               MaxNWts=numWts,
               trControl=ctrl)

stopCluster(cl) 
nnetFit

library(pROC)
p.nnet<-predict(nnetFit, newdata=final.valid, type="prob")
r<-roc(final.valid$retained,  p.nnet[,2])
r.nnet.auc<-r$auc
r.nnet.auc
#log neural net auc=0.6367

#install.packages("NeuralNetTools")
library(NeuralNetTools)
plotnet(nnetFit$finalModel, cex_val=0.8)



#RF Neural Net
library(dplyr)
summary(x)
x<-final.train[,terms.rf] 
x<-subset(x, select=-retained)

cl <- makePSOCKcluster(6) #Starts the parallel computing
registerDoParallel(cl)

nnetFit.rf<-train(x=x, y=final.train$retained, 
                  method="nnet", 
                  metric="ROC", 
                  linout=FALSE,
                  preProcess = c("range"), 
                  tuneGrid = tunegrid, 
                  
                  trace=FALSE,
                  maxit=100,
                  MaxNWts=numWts,
                  trControl=ctrl)

stopCluster(cl) 
nnetFit.rf

library(pROC)
p.nnet.rf<-predict(nnetFit.rf, newdata=final.valid, type="prob")
r.rf<-roc(final.valid$retained,  p.nnet.rf[,2])
r.nnet.rf.auc<-r.rf$auc
r.nnet.rf.auc
#log neural net auc=0.6286

library(NeuralNetTools)
plotnet(nnetFit.rf$finalModel, cex_val=0.8)





#Discriminant Analysis
install.packages("DiscriMiner")
library(DiscriMiner)
da.test<-final.train
da<-dplyr::select_if(da.test, is.numeric)

test.reg<-linDA(da, final.train$retained)
summary(test.reg)
test.reg$functions

propensity.leave<-exp(test.reg$scores[,2])/(exp(test.reg$scores[,1])+exp(test.reg$scores[,2]))
head(data.frame(Actual=final.train$retained, test.reg$classification, test.reg$scores, propensity.leave=propensity.leave))
#classified as leaving if the the leave function score is higher than the retain function score and vice versa








#COMPARISONS
library(knitr)
library(kableExtra)
results<-data.frame(
  Model=c("Full.Step", "Small.Step", "SO.Step", "Forest","Bag","GB.tree","Log.NN","RF.NN"),
  ROC.Valid=c(r.step.valid$auc, r.step.valid.2$auc, r.step.valid.3$auc,v.rforest.auc,p.bag.auc,r.gbtree.auc,r.nnet.auc,r.nnet.rf.auc),
  d.f.=c(df_step.1,df_step.2,df_step.3,"NA", "NA","NA","NA","NA")
)
knitr::kable(results) %>% 
  kable_styling(full_width=F)


#ROC curve plot
library(ggplot2)

roc<-list("Full.Step"=r.step.valid, "Small.Step"=r.step.valid.2, "SO.Step"=r.step.valid.3, 
          "Forest"=r.v,"Bag"=r.b,"GB.tree"=r.boost,
          "Log.NN"=r,"RF.NN"=r.rf)
p<-ggroc(roc)
p+scale_color_discrete(name="Model")+theme_bw()


#Best Model= reduced step
library(ROCR)
l.results<-data.frame(final.valid$retained, p.step.valid.2)
pred<-prediction(l.results$p.step.valid.2, l.results$final.valid.retained)
lift<-performance(pred, "lift", "rpp")
plot(lift, main="Lift Chart")

#variables for reduced step were chosen due to varible performance in full step and var importance found in random forest

#Cutoff
library(caret)
thresehold<-data.frame(lift@y.values, lift@alpha.values)
colnames(thresehold)<-c("lift", "cutoff")
head(thresehold)

sub<-subset(thresehold, lift>=1.5)
sub<-sub[order(sub$lift),]
sub[which.min(sub$cutoff),]
#cutoff=0.1101745

summary(step.2)

library(caret)
coords(r.step.valid.2, "best", ret="threshold", transpose = F)
data<-data.frame(p.step.valid.2, final.valid$retained)
preds<-as.factor(ifelse(p.step.valid.2>0.09231679,"Yes", "No"))
confusionMatrix(data=preds, reference=final.valid$retained, positive = "Yes")












########Other attempted 591 models:

#penalized logistic regression
#use lasso to impose sparsity on coefficients and make model more interpretable
install.packages("glmnet")
library(glmnet)
x<-model.matrix(~.,data=final.train)
cv.lasso<-cv.glmnet(x, final.train$retained, alpha=1, family="binomial")
plot(cv.lasso)
cv.lasso$lambda.min
coef(cv.lasso, cv.lasso$lambda.min)
coef(cv.lasso, cv.lasso$lambda.1se)

lasso.model <- glmnet(x, final.train$retained, alpha = 1, family = "binomial",
                      lambda = cv.lasso$lambda.min)
# Make prediction on test data
x.test <- model.matrix(retained ~., final.valid)[,-1]
library(dplyr)
pred <- predict(cv.lasso, s='lambda.min', newx=x[-(1:nrow(final.train)),],type="response")

str(final.train)
traintest=rbind(final.train,final.valid)
X = sparse.model.matrix(as.formula(paste("retained ~", paste(colnames(final.train[,-20]), sep = "", collapse=" +"))), data = traintest)
model = cv.glmnet(X[1:nrow(final.train),], final.train[,20], family = "binomial",type.measure = "auc",nfolds = 10)
plot(model)#gives auc but doesn't incorporate validation data
model$lambda.min
#predict on test set
pred = predict(model, s='lambda.min', newx=X[-(1:nrow(final.valid)),], type="response")
pred.valid<-roc(pred,final.valid$retained)
pred.valid$auc#doesn't work


#Generalized liner model?-not working
install.packages("randomGLM")
library(randomGLM)
RGLM = randomGLM(final.train, final.train$retained, nCandidateCovariates=ncol(final.train), nBags=30, keepModels = TRUE, nThreads = 1)
predicted = predict(RGLM, newdata = final.valid, type="class")
table(predicted, yTest)




#Discriminant function analysis (DFA) is a statistical procedure-
#that classifies unknown individuals and the probability of their- 
#classification into a certain group

install.packages("MASS")
install.packages("penalizedLDA")
library(penalizedLDA)
library(MASS)
attempt <- lda(retained ~., data=other.data, CV=F)
p.attempt.valid<-predict(attempt, newdata=final.valid, type="response")
r.attempt.valid<-roc(final.valid$retained, p.attempt.valid)
r.attempt.valid$auc
#valid step auc is 


#attempting to fix covariance
other.data<-final.train
other.data<-subset(other.data, select= -MiamiRanks)
other.data<-subset(other.data, select= -DateFrom)
str(other.data)




